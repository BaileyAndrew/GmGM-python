{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "import scipy.stats as stats\n",
    "from GmGM import GmGM, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_rank_one_update(U, S, V, a):\n",
    "    \"\"\"\n",
    "    Computes SVD of USV^T + a1^T via rank one update.\n",
    "    \"\"\"\n",
    "    p, r = U.shape\n",
    "    q, _ = V.shape\n",
    "\n",
    "    # Make sure this constitutes a valid SVD\n",
    "    assert S.shape == (r,)\n",
    "    assert a.shape == (p,)\n",
    "    assert U.shape == (p, r)\n",
    "    assert V.shape == (q, r)\n",
    "\n",
    "    # Orthogonal projection vectors\n",
    "    m = U.T @ a\n",
    "    P = a - U @ m\n",
    "    R_a = np.linalg.norm(P)\n",
    "    P /= R_a\n",
    "\n",
    "    n = V.sum(axis=0)\n",
    "    Q = 1 - V @ n\n",
    "    R_b = np.linalg.norm(Q)\n",
    "    Q /= R_b\n",
    "\n",
    "\n",
    "    # Create the K that should be eigendecomped\n",
    "    K1 = np.zeros((r+1, r+1))\n",
    "    np.fill_diagonal(K1[:r, :r], S)\n",
    "    K2 = (\n",
    "        np.concatenate((m, np.array([R_a]))).reshape(-1, 1)\n",
    "        @ np.concatenate((n, np.array([R_b]))).reshape(1, -1)\n",
    "    )\n",
    "    K = K1 + K2\n",
    "\n",
    "    # Inner eigendecomp\n",
    "    Up, Sf, VpT = np.linalg.svd(K)\n",
    "    Vp = VpT.T\n",
    "\n",
    "    # Results\n",
    "    Uf = np.hstack((U, P.reshape(-1, 1))) @ Up\n",
    "    Vf = np.hstack((V, Q.reshape(-1, 1))) @ Vp\n",
    "    \n",
    "    return Uf, Sf, Vf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_normal_map(X: sparse.sparray) -> tuple[sparse.sparray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Given a sparse matrix X (p by q), maps it to a normal distribution.\n",
    "    To preserve sparsity, we return the output expressed as a sum:\n",
    "    A + zeromaps @ np.ones(q)^T\n",
    "    where A has the same sparsity pattern as X, and zeromaps is a p-vector\n",
    "    containing the value (per-row) that zero was mapped to by the transformation.\n",
    "\n",
    "    This enables us to operate on a sparse matrix A, and use zeromaps later for\n",
    "    rank-one updates of those operations.  This helps avoid the need to densify.\n",
    "    \"\"\"\n",
    "    p, q = X.shape\n",
    "    A = X.copy()\n",
    "\n",
    "    zeromaps = np.zeros(p)\n",
    "    for i in range(p):\n",
    "        Y = X[[i], :].toarray()\n",
    "        cur = stats.rankdata(Y, axis=1)\n",
    "        cur = stats.norm.ppf(cur / (q+1))\n",
    "        if 0 in Y:\n",
    "            rank = (Y < 0).sum() + 1\n",
    "            zeromaps[i] = stats.norm.ppf(rank / (q+1))\n",
    "        else:\n",
    "            zeromaps[i] = 0\n",
    "        cur -= zeromaps[i]\n",
    "\n",
    "        # Looks complicated, but is needed because:\n",
    "        # X[[i], :] is not a view, and hence X[[i], :][Y != 0]\n",
    "        # is not assignable to!  (It sets values in a copy that gets\n",
    "        # immediately deleted)\n",
    "        A[np.ix_([i], (Y != 0).flatten())] = cur[Y != 0]\n",
    "\n",
    "    return A, zeromaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1.329557779806941e-13\n",
      "2.846674376856255e-13\n",
      "2.863427600972299e-13\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "p, q, r = 100, 50, 40\n",
    "s = 0.1\n",
    "\n",
    "# Generate data\n",
    "X = sparse.csr_array(sparse.random(p, q, density=s, format='csr'))\n",
    "\n",
    "# # Sparsity-preserving nonparanormal skeptic\n",
    "# zeromaps = np.zeros(p)\n",
    "# for i in range(p):\n",
    "#     Y = X[[i], :].toarray()\n",
    "#     cur = stats.rankdata(Y, axis=1)\n",
    "#     cur = stats.norm.ppf(cur / (q+1))\n",
    "#     if 0 in Y:\n",
    "#         rank = (Y < 0).sum() + 1\n",
    "#         zeromaps[i] = stats.norm.ppf(rank / (q+1))\n",
    "#     else:\n",
    "#         zeromaps[i] = 0\n",
    "#     cur -= zeromaps[i]\n",
    "\n",
    "#     # Looks complicated, but is needed because:\n",
    "#     # X[[i], :] is not a view, and hence X[[i], :][Y != 0]\n",
    "#     # is not assignable to!  (It sets values in a copy that gets\n",
    "#     # immediately deleted)\n",
    "#     X[np.ix_([i], (Y != 0).flatten())] = cur[Y != 0]\n",
    "\n",
    "X, zeromaps = sparse_normal_map(X)\n",
    "\n",
    "# Check the conversion has gone well\n",
    "X_ = stats.rankdata(X.toarray(), axis=1, method='min')\n",
    "X_ = stats.norm.ppf(X_ / (q+1))\n",
    "print(((X - X_ + zeromaps.reshape(-1, 1)) < 1e-10).all())\n",
    "\n",
    "\n",
    "# Compute SVD\n",
    "U, S, VT = sparse.linalg.svds(X, k=r)\n",
    "V = VT.T\n",
    "\n",
    "# Only compare to low-rank matrix:\n",
    "X = U @ np.diag(S) @ V.T\n",
    "\n",
    "# Rank one update\n",
    "a = zeromaps\n",
    "Uf, Sf, Vf = svd_rank_one_update(U, S, V, a)\n",
    "Xf = Uf @ np.diag(Sf) @ Vf.T\n",
    "\n",
    "# Ground truth\n",
    "Xt = X + a.reshape(-1, 1)\n",
    "Ut, St, VtT = np.linalg.svd(Xt)\n",
    "St = St[:r+1]\n",
    "Ut = Ut[:, :r+1]\n",
    "Vt = VtT.T[:, :r+1]\n",
    "\n",
    "# Results\n",
    "Sdiff = np.linalg.norm(St.flatten() - Sf.flatten())\n",
    "Udiff = np.linalg.norm(abs(Ut.T@Uf) - np.eye(r+1))\n",
    "Vdiff = np.linalg.norm(abs(Vt.T@Vf) - np.eye(r+1))\n",
    "print(Sdiff)\n",
    "print(Udiff)\n",
    "print(Vdiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dict[Modality, DataTensor]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mstructure\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dict[Modality, tuple[Axis]]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbatch_axes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[set[Axis]]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m      <no docstring>\n",
      "\u001b[0;31mFile:\u001b[0m           ~/mambaforge/envs/GmGM-python-accelerate/lib/python3.9/site-packages/GmGM/dataset.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "?Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/baileyandrew/mambaforge/envs/GmGM-python-accelerate/lib/python3.9/site-packages/GmGM/dataset.py:163: UserWarning: Trying to set a's tensor of type <class 'scipy.sparse._csr.csr_array'> to read-only, but this dataset has no `flags` attribute.  Making a copy instead.\n",
      "  warnings.warn(\n",
      "/Users/baileyandrew/mambaforge/envs/GmGM-python-accelerate/lib/python3.9/site-packages/GmGM/core/core.py:110: UserWarning: `nonparanormal_evec_backend` unspecified, defaulting to `COCA`\n",
      "  warnings.warn(\"`nonparanormal_evec_backend` unspecified, defaulting to `COCA`\")\n",
      "/Users/baileyandrew/mambaforge/envs/GmGM-python-accelerate/lib/python3.9/site-packages/GmGM/core/core.py:60: UserWarning: `nonparanormal_evec_backend` unspecified, defaulting to `COCA`\n",
      "  warnings.warn(\"`nonparanormal_evec_backend` unspecified, defaulting to `COCA`\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9966375\n"
     ]
    }
   ],
   "source": [
    "p, q, r = 400, 1000, 50\n",
    "s = 0.5\n",
    "\n",
    "# Generate data\n",
    "raw = sparse.csr_array(sparse.random(p, q, density=s, format='csr'))\n",
    "raw2 = raw.toarray()\n",
    "raw3 = raw.copy().toarray()\n",
    "X = Dataset(\n",
    "    dataset={\"a\": raw},\n",
    "    structure={\"a\": (\"b\", \"c\")},\n",
    ")\n",
    "Y = Dataset(\n",
    "    dataset={\"a\": raw2},\n",
    "    structure={\"a\": (\"b\", \"c\")},\n",
    ")\n",
    "\n",
    "a = GmGM(X, n_comps=r, verbose=False, to_keep=1, use_nonparanormal_skeptic=True).precision_matrices[\"b\"]\n",
    "b = GmGM(Y, n_comps=r, verbose=False, to_keep=1, use_nonparanormal_skeptic=True).precision_matrices[\"b\"]\n",
    "print(((a != 0).toarray() == (b != 0).toarray()).sum() / (p*p))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GmGM-python-accelerate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
